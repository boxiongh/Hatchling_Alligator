{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Brief Introduction:\n",
    "From Alligator_v01, you can efficiently train a binary classifier model by different first-order gradient descent optimisation algorithms, such as 1) **Gradient Descent**, 2) **GD with Momentum**, 3) **GD with RMSprop**, 4) **GD with Adam**. And all optimisations can also train with **Mini-batch** algorithm. A regularisation technique **L2 regulariser** also integrated with the model to improve the test/dev set performance. At the end of this notebook, results from the different algorithms would illustrated in a table wihch allow you to select a suitable optimiser for you.<br>\n",
    "\n",
    "## How to Use Alligator?\n",
    "To train your data by Alligator, you only need to provide the training and testing datasets in a correct format, then, this system will help you learn automatically and provide the comparison results at the end of this notebook in term of **train accuracy** and **testing accuracy**.<br>\n",
    "\n",
    "The input x should be flattened into a vector and in size of [$n_x, m$], where $n_x$ is the vectorised data for a single example, and $m$ is the number of the total examples. Then, pair with a labelled data (y) in size of [$1, m$].\n",
    "\n",
    "## Network Architecture and Functions Used:\n",
    "From this section, you will know the basic neural network architecture and the functions used to compute the cost, which could help you improve this model's performance.\n",
    "1. Neural network architecture:\n",
    "    - Inputs -> #[linear->Relu] -> [linear->Sigmoid] -> output\n",
    "    - The number of the neurons on each layer, and the number of hidden layers can be defined by your requirement. Your only required to provide the nerons on variable.\n",
    "2. Cost functions:\n",
    "    - Cross-entropy to compute the cost:<br>\n",
    "        $$ \\text{cost} = - \\frac{1}{m} \\sum^m_{i=1} \\sum^C_{j=1} y\\log{\\hat{y}} $$\n",
    "    - L2 Penalty:<br>\n",
    "        $$ \\text{L2 cost} = \\text{entropy cost}{red} + \\text{L2 penalty}\\\\\n",
    "        \\text{penalty} = \\frac{\\lambda}{2m} \\sum_l \\sum_k\\sum_j W_{k,j}^{[l]2} $$\n",
    "\n",
    "\n",
    "## Techniques/Parameters you can tune to improve the performace:\n",
    "1. **Learning rate**: - **'learning_rate = '**<br>\n",
    "    -> rate affects the convergent speed, and also the the final result to opmital value or around it.\n",
    "2. **Mini-batch size**: - **'mini_batch_size = '**\n",
    "3. **Layer's dimensions**: - **'layer_dims = '**<br>\n",
    "    -> #of neurons and #of layers can be considered in separate.\n",
    "4. **Optimiser**: - **'optimiser = '**<br>\n",
    "    -> Affect the speed and sometimes affect the accuracy<br>\n",
    "    -> 'momentum', 'rmsprop', 'adam' can be selected\n",
    "5. **Training time**: - **'num_epochs = '**\n",
    "5. **Lambda** for L2 Regularisation:  - **'lambd = '** <br>\n",
    "    -> Default set 'lambd = 0' to disable regularisation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Structure\n",
    "1. Section 1: Initialisation and Data Loading\n",
    "    - Import library\n",
    "    - Import data\n",
    "    - Define parameters and layer's dimensions\n",
    "2. Section 2: Network Architecture\n",
    "3. Section 3: Train model \n",
    "    - print_cost = True, to visualise the cost tendency along with updating\n",
    "4. Section 4: Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "from Hatchling_lib import *\n",
    "import h5py #for data loading\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import time\n",
    "\n",
    "#matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to test the optimisation performance from sklearn.datasets\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "def load_dataset(seed = 3, n_samples = 300): #Directly from sklearn in 2d points\n",
    "    np.random.seed(seed)\n",
    "    train_X, train_Y = sklearn.datasets.make_moons(n_samples, noise=.2) #300 #0.2 \n",
    "    # Visualize the data\n",
    "    # plt.scatter(train_X[:, 0], train_X[:, 1], c=train_Y, s=40, cmap=plt.cm.Spectral);\n",
    "    train_X = train_X.T\n",
    "    train_Y = train_Y.reshape((1, train_Y.shape[0]))\n",
    "    \n",
    "    return train_X, train_Y\n",
    "\n",
    "train_x, train_y = load_dataset(seed = 3, n_samples = 1000)\n",
    "test_x, test_y = load_dataset(seed = 2, n_samples = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters and layer's dimensions\n",
    "layer_dims = [train_x.shape[0], 20, 5, 1]\n",
    "\n",
    "# General set a following values:\n",
    "beta_1 = 0.9 # Moving average step for Momentum optimisation, ie. averaging around 10 time scales\n",
    "beta_2 = 0.999 # Moving step for RMSprop\n",
    "epsilon = 1e-8 # To avoid denominator blow up in RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hatchling_model(X, Y, layer_dims, optimiser = 'gd', learning_rate = 0.005, \n",
    "                    lambd = 0, mini_batch_size = 64, beta1 = 0.9, beta2 = 0.999,  \n",
    "                    epsilon = 1e-8, num_epochs = 5001, print_cost = True,\n",
    "                    mini_batch = True, plot_cost = False):\n",
    "\n",
    "    \"\"\"    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (2, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    layer_dims -- python list, containing the size of each layer\n",
    "    optimiser -- Updating model selection\n",
    "    learning_rate -- the learning rate, scalar\n",
    "    lambda -- L2 regularisation parameter, if =0, disable regularisaiton\n",
    "    mini_batch_size -- the size of a mini batch\n",
    "    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n",
    "    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n",
    "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
    "    num_epochs -- number of epochs (i.e. #iterations of whole train set)\n",
    "    print_cost -- True to print the cost every 1000 epochs\n",
    "\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    L = len(layer_dims)              # number of layers in the neural networks\n",
    "    costs = []                       # to keep track of the cost\n",
    "    t = 0                            # initializing the counter required for Adam update\n",
    "    m = X.shape[1]                   # number of training examples\n",
    "    grads = {}\n",
    "    seed = 5                         # To get constant random value, can be disabled when train your own model\n",
    "    \n",
    "    \n",
    "    # STEP 1: Initialise parameters\n",
    "    parameters = initialise_parameters_deep(layer_dims)\n",
    "\n",
    "    # Initialise the optimiser\n",
    "    if optimiser == \"gd\":\n",
    "        pass # no initialisation required for gradient descent, jump out this if-loop.\n",
    "    elif optimiser == \"momentum\":\n",
    "        v = initialise_velocity(parameters)\n",
    "    elif optimiser == \"RMSprop\":\n",
    "        s = initialise_RMSprop(parameters)\n",
    "    elif optimiser == \"adam\":\n",
    "        v, s = initialise_adam(parameters)\n",
    "    \n",
    "    # STEP 2: Optimisation loop\n",
    "    for i in range(num_epochs):\n",
    "        \n",
    "        if mini_batch: #Step 2 for model with mini-batch\n",
    "\n",
    "            # Define the random minibatches. \n",
    "            # Increment the seed to reshuffle differently the dataset after each epoch.\n",
    "            seed = seed + 1\n",
    "            mini_batches = random_mini_batches(X, Y, mini_batch_size, seed)\n",
    "            cost_total = 0\n",
    "\n",
    "            for minibatch in mini_batches:\n",
    "\n",
    "                 # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                # STEP 2.1: Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "                AL, caches = L_model_forward(minibatch_X, parameters)\n",
    "\n",
    "\n",
    "                # STEP 2.2: Compute cost by Binary Cross-Entropy cost\n",
    "                if lambd == 0: #i.e. no regularisation\n",
    "                    cost_total += bi_cross_entropy_cost(AL, minibatch_Y)\n",
    "                else:\n",
    "                    cost_total += cost_L2regularisation(AL, minibatch_Y, parameters, lambd)\n",
    "\n",
    "\n",
    "                # STEP 2.3: Backward propagation\n",
    "                if lambd == 0:\n",
    "                    grads = L_model_backward(AL, minibatch_Y, caches)\n",
    "                elif lambd != 0:\n",
    "                    grads = L_model_backward_L2regularisation(AL, minibatch_Y, caches, lambd)\n",
    "\n",
    "\n",
    "                # STEP 2.4: Update parameters\n",
    "                if optimiser == \"gd\":\n",
    "                    parameters = greedy_para_optimiser(parameters, grads, learning_rate)\n",
    "                elif optimiser == \"momentum\":\n",
    "                    t = t + 1 # Bias Correction counter\n",
    "                    parameters, v = momentum_para_optimiser(parameters, grads, v, t, beta1, learning_rate)\n",
    "                elif optimiser == \"RMSprop\":\n",
    "                    t = t + 1 # Bias Correction counter\n",
    "                    parameters, s = RMSprop_para_optimiser(parameters, grads, s, t, learning_rate, beta2, epsilon)\n",
    "                elif optimiser == \"adam\":\n",
    "                    t = t + 1 # Adam counter\n",
    "                    parameters, v, s = adam_para_optimiser(parameters, grads, v, s, t, learning_rate, beta1, beta2, epsilon)\n",
    "        \n",
    "        else: # Step 2 for gradient descent without mini-batch\n",
    "            cost_total = 0\n",
    "            \n",
    "            # STEP 2.1: Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "            AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        \n",
    "            # STEP 2.2: Compute cost by Binary Cross-Entropy cost\n",
    "            if lambd == 0: #i.e. no regularisation\n",
    "                cost_total += bi_cross_entropy_cost(AL, Y)\n",
    "            else:\n",
    "                cost_total += cost_L2regularisation(AL, Y, parameters, lambd)\n",
    "                \n",
    "            \n",
    "            # STEP 2.3: Backward propagation\n",
    "            if lambd == 0:\n",
    "                grads = L_model_backward(AL, Y, caches)\n",
    "            elif lambd != 0:\n",
    "                grads = L_model_backward_L2regularisation(AL, Y, caches, lambd)\n",
    "            \n",
    "            \n",
    "            # STEP 2.4: Update parameters\n",
    "            if optimiser == \"gd\":\n",
    "                parameters = greedy_para_optimiser(parameters, grads, learning_rate)\n",
    "            elif optimiser == \"momentum\":\n",
    "                t = t + 1 # Bias Correction counter\n",
    "                parameters, v = momentum_para_optimiser(parameters, grads, v, t, beta1, learning_rate)\n",
    "            elif optimiser == \"RMSprop\":\n",
    "                t = t + 1 # Bias Correction counter\n",
    "                parameters, s = RMSprop_para_optimiser(parameters, grads, s, t, learning_rate, beta2, epsilon)\n",
    "            elif optimiser == \"adam\":\n",
    "                t = t + 1 # Adam counter\n",
    "                parameters, v, s = adam_para_optimiser(parameters, grads, v, s, t, learning_rate, beta1, beta2, epsilon)\n",
    "        \n",
    "        \n",
    "        \n",
    "        cost_avg = cost_total / m # Average cost for each tain example\n",
    "        \n",
    "        \n",
    "        # Print the cost every 1000 training example or stop \n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" %(i, cost_avg))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost_avg)\n",
    "            \n",
    "    # plot the cost\n",
    "    if plot_cost:\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "    \n",
    "    return parameters\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost illustration for Gradient Descent:\n",
      "Cost after epoch 0: 0.000625\n",
      "Cost after epoch 1000: 0.000337\n",
      "Cost after epoch 2000: 0.000273\n",
      "Cost after epoch 3000: 0.000257\n",
      "Cost after epoch 4000: 0.000245\n",
      "Cost after epoch 5000: 0.000231\n",
      "Cost illustration for mini-batch Gradient Descent:\n",
      "Cost after epoch 0: 0.009942\n",
      "Cost after epoch 1000: 0.001531\n",
      "Cost after epoch 2000: 0.001113\n",
      "Cost after epoch 3000: 0.001057\n",
      "Cost after epoch 4000: 0.001038\n",
      "Cost after epoch 5000: 0.001043\n"
     ]
    }
   ],
   "source": [
    "## Train and Test the Model with difference optimiser\n",
    " # Gradient Descent without mini-batch\n",
    "start_time1 = time.time()\n",
    "print('Cost illustration for Gradient Descent:')\n",
    "para_gd = Hatchling_model(train_x, train_y, layer_dims=layer_dims, optimiser = 'gd', print_cost = True, mini_batch = False)\n",
    "end_time1 = time.time()\n",
    "t1 = end_time1 - start_time1\n",
    "train_acc_gd, train_pred_greedy = bi_Classfier_predict(train_x, train_y, para_gd)\n",
    "test_acc_gd, test_pred_greedy = bi_Classfier_predict(test_x, test_y, para_gd)\n",
    "\n",
    "\n",
    " # Mini-batch Gradient Descent\n",
    "start_time2 = time.time()\n",
    "print('Cost illustration for mini-batch Gradient Descent:')\n",
    "para_gd_mini = Hatchling_model(train_x, train_y, layer_dims=layer_dims, optimiser = 'gd', print_cost = True)\n",
    "end_time2 = time.time()\n",
    "t2 = end_time2 - start_time2\n",
    "train_acc_gdmini, train_pred_gdmini = bi_Classfier_predict(train_x, train_y, para_gd_mini)\n",
    "test_acc_gdmini, test_pred_gdmini = bi_Classfier_predict(test_x, test_y, para_gd_mini)\n",
    "\n",
    "\n",
    " # Mini-batch Gradient Descent with L2 Regularisation\n",
    "start_time3 = time.time()\n",
    "para_L2mini = Hatchling_model(train_x, train_y, layer_dims=layer_dims, optimiser = 'gd', lambd = 0.90, print_cost = False)\n",
    "end_time3 = time.time()\n",
    "t3 = end_time3 - start_time3\n",
    "train_acc_L2mini, train_pred_L2mini = bi_Classfier_predict(train_x, train_y, para_L2mini)\n",
    "test_acc_L2mini, test_pred_L2mini = bi_Classfier_predict(test_x, test_y, para_L2mini)\n",
    "\n",
    "\n",
    " # Mini-batch Gradient Descent by Momentum\n",
    "start_time4 = time.time()\n",
    "para_momentum_mini = Hatchling_model(train_x, train_y, layer_dims=layer_dims, optimiser = 'momentum', print_cost = False)\n",
    "end_time4 = time.time()\n",
    "t4 = end_time4 - start_time4\n",
    "train_acc_momentmini, train_pred_momentmini = bi_Classfier_predict(train_x, train_y, para_momentum_mini)\n",
    "test_acc_momentmini, test_pred_momentmini = bi_Classfier_predict(test_x, test_y, para_momentum_mini)\n",
    "\n",
    "\n",
    " # Mini-batch Gradient Descent by RMSprop\n",
    "start_time5 = time.time()\n",
    "para_rmsprop = Hatchling_model(train_x, train_y, layer_dims = layer_dims, optimiser = 'RMSprop', print_cost = False)\n",
    "end_time5 = time.time()\n",
    "t5 = end_time5 - start_time5\n",
    "train_acc_rmsmini, train_pred_rmsmini = bi_Classfier_predict(train_x, train_y, para_rmsprop)\n",
    "test_acc_rmsmini, test_pred_rmsmini = bi_Classfier_predict(test_x, test_y, para_rmsprop)\n",
    "\n",
    "\n",
    " # Mini-batch Gradient Descent by Adam\n",
    "start_time6 = time.time()\n",
    "para_adam = Hatchling_model(train_x, train_y, layer_dims=layer_dims, optimiser = 'adam', print_cost = False)\n",
    "end_time6 = time.time()\n",
    "t6 = end_time6 - start_time6\n",
    "train_acc_adammini, train_pred_adamini = bi_Classfier_predict(train_x, train_y, para_adam)\n",
    "test_acc_adamini, test_pred_adamini = bi_Classfier_predict(test_x, test_y, para_adam)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "if __name__ == \"__main__\":    \n",
    "    data = {\"Algorithm\": ['gradient descent', 'mini gd', 'mini gd_L2', 'mini momentum', 'mini rmsprop', 'mini adam'],\n",
    "            \"Train acc\": [format(train_acc_gd,'.3f'), format(train_acc_gdmini,'.3f'), format(train_acc_L2mini,'.3f'), format(train_acc_momentmini,'.3f'), format(train_acc_rmsmini,'.3f'), format(train_acc_adammini,'.3f')],        \n",
    "            \"Test acc\": [format(test_acc_gd,'.3f'), format(test_acc_gdmini,'.3f'), format(test_acc_L2mini,'.3f'), format(test_acc_momentmini,'.3f'), format(test_acc_rmsmini,'.3f'), format(test_acc_adamini,'.3f')],\n",
    "            \"Train time\":[(format(t1,'.2f')+' s'), (format(t2,'.2f')+' s'), (format(t3,'.2f')+' s'), (format(t4,'.2f')+' s'), (format(t5,'.2f')+' s'), (format(t6,'.2f')+' s')]} \n",
    "\n",
    "    df = pd.DataFrame(data)    \n",
    "    fig, ax = plt.subplots(figsize=(7, 7))    \n",
    "    ax.axis(\"off\")    \n",
    "    ax.axis(\"tight\")    \n",
    "    tb = ax.table(cellText=df.values, colLabels=df.columns, bbox=[0, 0, 1, 1],)    \n",
    "    tb[0, 0].set_facecolor(\"#363636\")    \n",
    "    tb[0, 1].set_facecolor(\"#363636\")   \n",
    "    tb[0, 2].set_facecolor(\"#363636\")    \n",
    "    tb[0, 0].set_text_props(color=\"w\")    \n",
    "    tb[0, 1].set_text_props(color=\"w\")   \n",
    "    tb[0, 2].set_text_props(color=\"w\") \n",
    "    tb[0, 3].set_facecolor(\"#363636\")    \n",
    "    tb[0, 3].set_text_props(color=\"w\")    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
